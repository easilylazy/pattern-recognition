{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import torch\r\n",
                "import torch.nn as nn\r\n",
                "import torch.nn.functional as F\r\n",
                "import torch.optim as optim\r\n",
                "\r\n",
                "from torchtext.legacy import data\r\n",
                "from torchtext.legacy import datasets\r\n",
                "from torchtext.vocab import Vectors, GloVe, CharNGram#, FastTex\r\n",
                "\r\n",
                "torch.manual_seed(1)\r\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<torch._C.Generator at 0x159192a7410>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 1
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "################################\r\n",
                "# DataLoader\r\n",
                "################################\r\n",
                "\r\n",
                "# set up fields\r\n",
                "TEXT = data.Field()\r\n",
                "LABEL = data.Field(sequential=False,dtype=torch.long)\r\n",
                "\r\n",
                "# make splits for data\r\n",
                "# DO NOT MODIFY: fine_grained=True, train_subtrees=False\r\n",
                "train, val, test = datasets.SST.splits(\r\n",
                "    TEXT, LABEL, fine_grained=True, train_subtrees=False)\r\n",
                "\r\n",
                "# print information about the data\r\n",
                "print('train.fields', train.fields)\r\n",
                "print('len(train)', len(train))\r\n",
                "print('vars(train[0])', vars(train[0]))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "train.fields {'text': <torchtext.legacy.data.field.Field object at 0x0000015915A63288>, 'label': <torchtext.legacy.data.field.Field object at 0x0000015915A63248>}\n",
                        "len(train) 8544\n",
                        "vars(train[0]) {'text': ['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'Century', \"'s\", 'new', '``', 'Conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'Arnold', 'Schwarzenegger', ',', 'Jean-Claud', 'Van', 'Damme', 'or', 'Steven', 'Segal', '.'], 'label': 'positive'}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "\r\n",
                "# build the vocabulary\r\n",
                "# you can use other pretrained vectors, refer to https://github.com/pytorch/text/blob/master/torchtext/vocab.py\r\n",
                "TEXT.build_vocab(train, vectors=Vectors(name='vector.txt', cache='./data'))\r\n",
                "LABEL.build_vocab(train)\r\n",
                "# We can also see the vocabulary directly using either the stoi (string to int) or itos (int to string) method.\r\n",
                "print(TEXT.vocab.itos[:10])\r\n",
                "print(LABEL.vocab.stoi)\r\n",
                "print(TEXT.vocab.freqs.most_common(20))\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['<unk>', '<pad>', '.', ',', 'the', 'and', 'a', 'of', 'to', \"'s\"]\n",
                        "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x0000015965328F88>>, {'<unk>': 0, 'positive': 1, 'negative': 2, 'neutral': 3, 'very positive': 4, 'very negative': 5})\n",
                        "[('.', 8024), (',', 7131), ('the', 6037), ('and', 4431), ('a', 4403), ('of', 4386), ('to', 2995), (\"'s\", 2544), ('is', 2536), ('that', 1915), ('in', 1789), ('it', 1775), ('The', 1265), ('as', 1200), ('film', 1152), ('but', 1076), ('with', 1071), ('for', 963), ('movie', 959), ('its', 912)]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "len(LABEL.vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "6"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "\r\n",
                "# print vocab information\r\n",
                "print('len(TEXT.vocab)', len(TEXT.vocab))\r\n",
                "print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "len(TEXT.vocab) 18282\n",
                        "TEXT.vocab.vectors.size() torch.Size([18282, 300])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "\r\n",
                "# make iterator for splits\r\n",
                "train_iter, val_iter, test_iter = data.BucketIterator.splits(\r\n",
                "    (train, val, test), batch_size=64)\r\n",
                "\r\n",
                "# print batch information\r\n",
                "batch = next(iter(train_iter)) # for batch in train_iter\r\n",
                "print(batch.text) # input sequence\r\n",
                "print(batch.label) # groud truth\r\n",
                "\r\n",
                "# Attention: batch.label in the range [1,5] not [0,4] !!!"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[  22,  109,   22,  ..., 2966,   14, 6272],\n",
                        "        [ 471,    4, 1376,  ..., 1021, 1369,   19],\n",
                        "        [   3,   88,  128,  ..., 4841,   10, 1287],\n",
                        "        ...,\n",
                        "        [   1,    1,    1,  ...,    1,    1,    1],\n",
                        "        [   1,    1,    1,  ...,    1,    1,    1],\n",
                        "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
                        "tensor([4, 3, 3, 1, 3, 3, 4, 2, 1, 1, 4, 4, 2, 3, 1, 5, 3, 2, 4, 2, 1, 1, 5, 1,\n",
                        "        1, 3, 3, 1, 3, 1, 1, 2, 1, 2, 2, 5, 5, 5, 3, 1, 4, 3, 4, 3, 4, 3, 1, 4,\n",
                        "        5, 4, 3, 2, 3, 3, 1, 2, 2, 2, 2, 4, 2, 1, 1, 3])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "\r\n",
                "\r\n",
                "################################\r\n",
                "# After build your network \r\n",
                "################################\r\n",
                "\r\n",
                "\r\n",
                "# Copy the pre-trained word embeddings we loaded earlier into the embedding layer of our model.\r\n",
                "pretrained_embeddings = TEXT.vocab.vectors\r\n",
                "\r\n",
                "print(pretrained_embeddings.shape)\r\n",
                "\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([18282, 300])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "\r\n",
                "\r\n",
                "\r\n",
                "class LSTMTagger(nn.Module):\r\n",
                "\r\n",
                "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\r\n",
                "        super(LSTMTagger, self).__init__()\r\n",
                "        self.hidden_dim = hidden_dim\r\n",
                "\r\n",
                "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\r\n",
                "\r\n",
                "        # The LSTM takes word embeddings as inputs, and outputs hidden states\r\n",
                "        # with dimensionality hidden_dim.\r\n",
                "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\r\n",
                "\r\n",
                "        # The linear layer that maps from hidden state space to tag space\r\n",
                "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\r\n",
                "\r\n",
                "    def forward(self, sentence):\r\n",
                "        embeds = self.word_embeddings(sentence)\r\n",
                "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\r\n",
                "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\r\n",
                "        tag_scores = F.log_softmax(tag_space, dim=1)\r\n",
                "        return tag_scores\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "EMBEDDING_DIM=300\r\n",
                "HIDDEN_DIM=10\r\n",
                "batch_size=32"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\r\n",
                "# make iterator for splits\r\n",
                "train_iter, val_iter, test_iter = data.BucketIterator.splits(\r\n",
                "    (train, val, test), batch_size=batch_size)\r\n",
                "\r\n",
                "# print batch information\r\n",
                "batch = next(iter(train_iter)) # for batch in train_iter\r\n",
                "# print(batch.text) # input sequence\r\n",
                "# print(batch.label) # groud truth\r\n",
                "\r\n",
                "# Attention: batch.label in the range [1,5] not [0,4] !!!"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "from torch.autograd import Variable\r\n",
                "for epoch in range(100):  # again, normally you would NOT do 300 epochs, it is toy data\r\n",
                "    batch = next(iter(train_iter)) # for batch in train_iter\r\n",
                "    tag_scores=torch.zeros((batch_size,6))\r\n",
                "    for i in range(batch_size):\r\n",
                "    # for sentence, tags in batch:\r\n",
                "        sentence=batch.text[:,i]\r\n",
                "        tags=batch.label[i]\r\n",
                "        # Step 1. Remember that Pytorch accumulates gradients.\r\n",
                "        # We need to clear them out before each instance\r\n",
                "        model.zero_grad()\r\n",
                "\r\n",
                "        # Step 2. Get our inputs ready for the network, that is, turn them into\r\n",
                "        # Tensors of word indices.\r\n",
                "        sentence_in = sentence\r\n",
                "        #prepare_sequence(sentence, word_to_ix)\r\n",
                "        # targets = tags\r\n",
                "        # prepare_sequence(tags, tag_to_ix)\r\n",
                "\r\n",
                "        # Step 3. Run our forward pass.\r\n",
                "        tag_scores[i]=(model(sentence_in)[-1])\r\n",
                "\r\n",
                "        # Step 4. Compute the loss, gradients, and update the parameters by\r\n",
                "        #  calling optimizer.step()\r\n",
                "    targets=batch.label\r\n",
                "    tag_scores=Variable(tag_scores,requires_grad=True)\r\n",
                "    loss = loss_function(tag_scores, targets)\r\n",
                "    loss.backward()\r\n",
                "    optimizer.step()\r\n",
                "    print(loss)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor(1.8020, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7674, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8209, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7702, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7882, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7753, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8245, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8182, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8101, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7804, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7995, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7684, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8350, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7911, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7959, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8024, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7654, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7774, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7935, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7940, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7447, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8594, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7908, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7631, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7962, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8038, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7879, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7515, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8101, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8195, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8312, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8132, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7529, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7271, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7998, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7765, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7654, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7833, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7741, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7477, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8263, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7168, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7958, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8229, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8302, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7631, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8215, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8250, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8098, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8068, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8332, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7872, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7888, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7603, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7558, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8380, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7461, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7967, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7770, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8247, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8135, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7943, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7714, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7923, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7996, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7889, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7956, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7597, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7350, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8215, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7740, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7545, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8166, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7758, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7901, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7287, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8152, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7572, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7966, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8329, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7791, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7633, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7792, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7959, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7910, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8026, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8593, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8197, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7771, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8038, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7794, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7692, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7393, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7736, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7770, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7086, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8143, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.8071, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7677, grad_fn=<NllLossBackward>)\n",
                        "tensor(1.7292, grad_fn=<NllLossBackward>)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from torch.autograd import Variable\r\n",
                "for epoch in range(100):  # again, normally you would NOT do 300 epochs, it is toy data\r\n",
                "    batch = next(iter(train_iter)) # for batch in train_iter\r\n",
                "    tag_scores=torch.zeros((batch_size,6))\r\n",
                "    for i in range(batch_size):\r\n",
                "    # for sentence, tags in batch:\r\n",
                "        sentence=batch.text[:,i]\r\n",
                "        tags=batch.label[i]\r\n",
                "        # Step 1. Remember that Pytorch accumulates gradients.\r\n",
                "        # We need to clear them out before each instance\r\n",
                "        model.zero_grad()\r\n",
                "\r\n",
                "        # Step 2. Get our inputs ready for the network, that is, turn them into\r\n",
                "        # Tensors of word indices.\r\n",
                "        sentence_in = sentence\r\n",
                "        #prepare_sequence(sentence, word_to_ix)\r\n",
                "        # targets = tags\r\n",
                "        # prepare_sequence(tags, tag_to_ix)\r\n",
                "\r\n",
                "        # Step 3. Run our forward pass.\r\n",
                "        tag_scores[i]=(model(sentence_in)[-1])\r\n",
                "\r\n",
                "        # Step 4. Compute the loss, gradients, and update the parameters by\r\n",
                "        #  calling optimizer.step()\r\n",
                "    targets=batch.label\r\n",
                "    tag_scores=Variable(tag_scores,requires_grad=True)\r\n",
                "    loss = loss_function(tag_scores, targets)\r\n",
                "    loss.backward()\r\n",
                "    optimizer.step()\r\n",
                "    print(loss)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "loss_function(tag_scores, targets-1)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor(1.8102, grad_fn=<NllLossBackward>)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 23
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "loss_function(tag_scores, targets)\r\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor(1.7965, grad_fn=<NllLossBackward>)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 24
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                " # See what the scores are after training\r\n",
                "with torch.no_grad():\r\n",
                "       # for epoch in range(100):  # again, normally you would NOT do 300 epochs, it is toy data\r\n",
                "        batch = next(iter(train_iter)) # for batch in train_iter\r\n",
                "        tag_scores=torch.zeros((batch_size,6))\r\n",
                "        for i in range(batch_size):\r\n",
                "        # for sentence, tags in batch:\r\n",
                "            sentence=batch.text[:,i]\r\n",
                "            # tags=batch.label[i]\r\n",
                "            tag_scores[i]=(model(sentence)[-1])\r\n",
                "\r\n",
                "        # Step 4. Compute the loss, gradients, and update the parameters by\r\n",
                "        #  calling optimizer.step()\r\n",
                "        targets=batch.label\r\n",
                "        tag_scores=Variable(tag_scores,requires_grad=True)\r\n",
                "        print(tag_scores.argmax(axis=1))\r\n",
                "        print(targets)\r\n",
                "\r\n",
                "        # loss = loss_function(tag_scores, targets)\r\n",
                "        # loss.backward()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
                        "        4, 4, 4, 4, 4, 4, 4, 4])\n",
                        "tensor([1, 3, 4, 2, 3, 1, 1, 4, 3, 4, 1, 4, 2, 5, 3, 3, 1, 4, 4, 3, 4, 5, 1, 5,\n",
                        "        3, 4, 3, 2, 5, 4, 3, 2])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\r\n",
                "# See what the scores are after training\r\n",
                "with torch.no_grad():\r\n",
                "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\r\n",
                "    tag_scores = model(inputs)\r\n",
                "\r\n",
                "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\r\n",
                "    # for word i. The predicted tag is the maximum scoring tag.\r\n",
                "    # Here, we can see the predicted sequence below is 0 1 2 0 1\r\n",
                "    # since 0 is index of the maximum value of row 1,\r\n",
                "    # 1 is the index of maximum value of row 2, etc.\r\n",
                "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\r\n",
                "    print(tag_scores)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "tag_scores"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor([[-1.9543, -1.9938, -1.7600, -1.7788, -1.4444, -1.9282],\n",
                            "        [-1.9283, -1.9466, -1.7319, -1.7936, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9466, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9473, -2.0759, -1.7619, -1.7907, -1.4517, -1.8377],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9466, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9465, -1.7319, -1.7936, -1.4341, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9466, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9290, -1.9450, -1.7332, -1.7924, -1.4351, -2.0374],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9289, -1.9443, -1.7337, -1.7923, -1.4355, -2.0371],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0389],\n",
                            "        [-1.9283, -1.9466, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9466, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9465, -1.7320, -1.7935, -1.4341, -2.0388],\n",
                            "        [-1.9627, -2.0559, -1.6628, -1.8291, -1.3920, -2.0189],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9465, -1.7320, -1.7934, -1.4341, -2.0387],\n",
                            "        [-1.9283, -1.9466, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0389],\n",
                            "        [-1.9284, -1.9462, -1.7322, -1.7934, -1.4342, -2.0386],\n",
                            "        [-1.9283, -1.9466, -1.7320, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9295, -1.9434, -1.7345, -1.7915, -1.4362, -2.0361],\n",
                            "        [-1.9283, -1.9467, -1.7319, -1.7935, -1.4340, -2.0388],\n",
                            "        [-1.9287, -1.9459, -1.7326, -1.7930, -1.4344, -2.0381]],\n",
                            "       requires_grad=True)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 29
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.4",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.4 64-bit"
        },
        "interpreter": {
            "hash": "3f857618d8b6a3d270a8a45aea13fd0dc2a28a907e8d4ef70fe87ce2a92698f8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}