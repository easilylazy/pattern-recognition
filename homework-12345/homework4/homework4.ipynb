{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c39dd8454138eeaae7582c1b8b9112000612a2e483c721ee49090cb6d3cfebe8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import input_data\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "mnist_dataset = input_data.read_data_sets('..\\homework-2\\MNIST_data', one_hot=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ..\\homework-2\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ..\\homework-2\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ..\\homework-2\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ..\\homework-2\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "train_dataloader = DataLoader(mnist_dataset.train, batch_size=64, shuffle=True)\r\n",
    "test_dataloader = DataLoader(mnist_dataset.test, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Display image and label.\r\n",
    "train_features, train_labels = next(iter(train_dataloader))\r\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\r\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\r\n",
    "img = train_features[0].squeeze().reshape((28,28))\r\n",
    "label = train_labels[0]\r\n",
    "plt.imshow(img, cmap=\"gray\")\r\n",
    "plt.show()\r\n",
    "print(f\"Label: {label}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature batch shape: torch.Size([64, 784])\n",
      "Labels batch shape: torch.Size([64, 10])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "image.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "label.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "\r\n",
    "class Net(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        # 1 input image channel, 6 output channels, 7x7 square convolution\r\n",
    "        # kernel\r\n",
    "        self.conv1 = nn.Conv2d(1,8,3,1,1)\r\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3,1,1)\r\n",
    "        # an affine operation: y = Wx + b\r\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 128)  # 7*7 from image dimension\r\n",
    "        self.fc2 = nn.Linear(128, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # Max pooling over a (2, 2) window\r\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\r\n",
    "        # If the size is a square, you can specify with a single number\r\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\r\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "net = Net()\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "input = torch.randn(1, 1, 28, 28)\r\n",
    "out = net(input)\r\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.0420, -0.0437, -0.0061,  0.0443,  0.0258,  0.0962,  0.0337, -0.0634,\n",
      "          0.1032, -0.1711]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "output = net(input)\r\n",
    "target = torch.randn(10)  # a dummy target, for example\r\n",
    "target = target.view(1, -1)  # make it the same shape as output\r\n",
    "criterion = nn.MSELoss()\r\n",
    "\r\n",
    "loss = criterion(output, target)\r\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.9993, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "# create your optimizer\r\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\r\n",
    "\r\n",
    "# in your training loop:\r\n",
    "optimizer.zero_grad()   # zero the gradient buffers\r\n",
    "output = net(input)\r\n",
    "loss = criterion(output, target)\r\n",
    "loss.backward()\r\n",
    "optimizer.step()    # Does the updat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        # Compute prediction and loss\r\n",
    "        X=X.reshape(X.shape[0],1,28,28)\r\n",
    "        pred = model(X)\r\n",
    "        loss = loss_fn(pred, y.float())\r\n",
    "\r\n",
    "        # Backpropagation\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        if batch % 100 == 0:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\r\n",
    "\r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    num_batches = len(dataloader)\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, y in dataloader:\r\n",
    "            X=X.reshape(X.shape[0],1,28,28)\r\n",
    "            pred = model(X)\r\n",
    "            test_loss += loss_fn(pred, y.float()).item()\r\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\r\n",
    "\r\n",
    "    test_loss /= num_batches\r\n",
    "    correct /= size\r\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "# create your optimizer\r\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\r\n",
    "criterion = nn.MSELoss()\r\n",
    "loss_fn=criterion\r\n",
    "train_loop(train_dataloader, net, loss_fn, optimizer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss: 0.099750  [    0/55000]\n",
      "loss: 0.096472  [ 6400/55000]\n",
      "loss: 0.091240  [12800/55000]\n",
      "loss: 0.090777  [19200/55000]\n",
      "loss: 0.090016  [25600/55000]\n",
      "loss: 0.089679  [32000/55000]\n",
      "loss: 0.089540  [38400/55000]\n",
      "loss: 0.088702  [44800/55000]\n",
      "loss: 0.089292  [51200/55000]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "test_loop(test_dataloader, net, loss_fn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 0.089011 \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "loss_fn =  nn.MSELoss()\r\n",
    "#nn.CrossEntropyLoss()\r\n",
    "model=net\r\n",
    "learning_rate=0.01\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for t in range(epochs):\r\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\r\n",
    "    test_loop(test_dataloader, model, loss_fn)\r\n",
    "print(\"Done!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.088971  [    0/55000]\n",
      "loss: 0.089108  [ 6400/55000]\n",
      "loss: 0.088839  [12800/55000]\n",
      "loss: 0.088776  [19200/55000]\n",
      "loss: 0.088461  [25600/55000]\n",
      "loss: 0.088963  [32000/55000]\n",
      "loss: 0.088308  [38400/55000]\n",
      "loss: 0.088682  [44800/55000]\n",
      "loss: 0.088109  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.088135 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.087905  [    0/55000]\n",
      "loss: 0.087833  [ 6400/55000]\n",
      "loss: 0.087753  [12800/55000]\n",
      "loss: 0.087971  [19200/55000]\n",
      "loss: 0.087636  [25600/55000]\n",
      "loss: 0.087572  [32000/55000]\n",
      "loss: 0.087318  [38400/55000]\n",
      "loss: 0.087032  [44800/55000]\n",
      "loss: 0.086954  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 0.086798 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.086825  [    0/55000]\n",
      "loss: 0.086707  [ 6400/55000]\n",
      "loss: 0.086408  [12800/55000]\n",
      "loss: 0.086261  [19200/55000]\n",
      "loss: 0.085823  [25600/55000]\n",
      "loss: 0.085904  [32000/55000]\n",
      "loss: 0.084958  [38400/55000]\n",
      "loss: 0.085268  [44800/55000]\n",
      "loss: 0.084846  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.084322 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.084160  [    0/55000]\n",
      "loss: 0.083836  [ 6400/55000]\n",
      "loss: 0.083371  [12800/55000]\n",
      "loss: 0.082947  [19200/55000]\n",
      "loss: 0.083436  [25600/55000]\n",
      "loss: 0.081069  [32000/55000]\n",
      "loss: 0.080744  [38400/55000]\n",
      "loss: 0.079999  [44800/55000]\n",
      "loss: 0.080688  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.079258 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.078357  [    0/55000]\n",
      "loss: 0.079096  [ 6400/55000]\n",
      "loss: 0.076972  [12800/55000]\n",
      "loss: 0.078774  [19200/55000]\n",
      "loss: 0.075939  [25600/55000]\n",
      "loss: 0.074925  [32000/55000]\n",
      "loss: 0.070662  [38400/55000]\n",
      "loss: 0.070594  [44800/55000]\n",
      "loss: 0.072100  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.069450 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.068518  [    0/55000]\n",
      "loss: 0.067929  [ 6400/55000]\n",
      "loss: 0.068475  [12800/55000]\n",
      "loss: 0.066029  [19200/55000]\n",
      "loss: 0.065966  [25600/55000]\n",
      "loss: 0.059592  [32000/55000]\n",
      "loss: 0.060094  [38400/55000]\n",
      "loss: 0.061362  [44800/55000]\n",
      "loss: 0.060543  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.059135 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.059145  [    0/55000]\n",
      "loss: 0.055730  [ 6400/55000]\n",
      "loss: 0.057274  [12800/55000]\n",
      "loss: 0.057098  [19200/55000]\n",
      "loss: 0.058601  [25600/55000]\n",
      "loss: 0.059474  [32000/55000]\n",
      "loss: 0.058635  [38400/55000]\n",
      "loss: 0.053742  [44800/55000]\n",
      "loss: 0.053448  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.052101 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.047715  [    0/55000]\n",
      "loss: 0.053902  [ 6400/55000]\n",
      "loss: 0.050600  [12800/55000]\n",
      "loss: 0.051140  [19200/55000]\n",
      "loss: 0.050187  [25600/55000]\n",
      "loss: 0.045927  [32000/55000]\n",
      "loss: 0.051209  [38400/55000]\n",
      "loss: 0.044339  [44800/55000]\n",
      "loss: 0.051062  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.046308 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.047681  [    0/55000]\n",
      "loss: 0.044387  [ 6400/55000]\n",
      "loss: 0.050925  [12800/55000]\n",
      "loss: 0.041334  [19200/55000]\n",
      "loss: 0.043826  [25600/55000]\n",
      "loss: 0.041823  [32000/55000]\n",
      "loss: 0.040764  [38400/55000]\n",
      "loss: 0.043192  [44800/55000]\n",
      "loss: 0.041339  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.041215 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.039821  [    0/55000]\n",
      "loss: 0.038676  [ 6400/55000]\n",
      "loss: 0.040519  [12800/55000]\n",
      "loss: 0.042342  [19200/55000]\n",
      "loss: 0.036210  [25600/55000]\n",
      "loss: 0.048308  [32000/55000]\n",
      "loss: 0.034976  [38400/55000]\n",
      "loss: 0.038033  [44800/55000]\n",
      "loss: 0.030638  [51200/55000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.037157 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}