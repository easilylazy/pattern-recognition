{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd03f857618d8b6a3d270a8a45aea13fd0dc2a28a907e8d4ef70fe87ce2a92698f8",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "author: leezeeyee   \n",
    "date: 2021/4/16  \n",
    "link: [github](https://github.com/easilylazy/pattern-recognition) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           1           5.1          3.5           1.4          0.2  setosa\n",
       "1           2           4.9          3.0           1.4          0.2  setosa\n",
       "2           3           4.7          3.2           1.3          0.2  setosa\n",
       "3           4           4.6          3.1           1.5          0.2  setosa\n",
       "4           5           5.0          3.6           1.4          0.2  setosa"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "irisData=pd.read_csv('../multiClass/iris.csv')\n",
    "irisData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 0              81\n",
       "Sepal.Length           5.5\n",
       "Sepal.Width            2.4\n",
       "Petal.Length           3.8\n",
       "Petal.Width            1.1\n",
       "Species         versicolor\n",
       "Name: 80, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "irisData.iloc[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDict={}\n",
    "labelDict['setosa']=0\n",
    "labelDict['versicolor']=1\n",
    "labelDict['virginica']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=irisData[['Sepal.Length',\t'Sepal.Width',\t'Petal.Length',\t'Petal.Width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "setosa\n0\nversicolor\n1\nvirginica\n2\n"
     ]
    }
   ],
   "source": [
    "labels=np.zeros(len(data))\n",
    "\n",
    "for key in labelDict:\n",
    "    print(key)\n",
    "    print(labelDict[key])\n",
    "    # print( irisData[irisData['Species']==key].index.tolist())\n",
    "    labels[irisData[irisData['Species']==key].index.tolist()]=labelDict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data\n",
    "one_hot_Y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17 13 20 25  8 26 49  0 35 28  6 22 36 24 34 46  2 12 16  3 43  7  9 38\n",
      "  5 41 11 47 15  4 44 40 29 23 31 37 33 21 30 14 39 48 18 10 42 45 27 32\n",
      "  1 19]\n",
      "[71 55 96 80 64 85 91 62 90 53 54 98 86 93 59 76 99 52 51 66 97 83 94 63\n",
      " 81 58 82 68 61 65 73 78 50 69 77 57 92 95 56 89 74 87 67 84 70 79 60 72\n",
      " 88 75]\n",
      "[149 128 112 100 115 108 106 134 105 147 136 130 146 117 111 132 138 109\n",
      " 143 124 121 120 113 145 116 141 119 135 133 148 118 107 131 114 137 122\n",
      " 125 103 123 110 144 140 129 127 142 104 102 126 139 101]\n",
      "[5.9 3.  5.1 1.8]\n",
      "[5.9 3.  5.1 1.8]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[6.5, 3. , 5.2, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.5, 2.4, 3.7, 1. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "trainX=[]\n",
    "trainY=[]\n",
    "testX=[]\n",
    "testY=[]\n",
    "\n",
    "for i in range(3):\n",
    "    index=np.where(labels==i)[0]\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    trainX.append(X[index[:30]])\n",
    "    trainY.append(labels[index[:30]])\n",
    "    testX.append(X[index[30:]])\n",
    "    testY.append(labels[index[30:]])\n",
    "    print(index)\n",
    "print(trainX[2][0])\n",
    "print(X[index[0]])\n",
    "trainX_all=np.r_[trainX[0],trainX[1],trainX[2]]\n",
    "trainY_all=np.r_[trainY[0],trainY[1],trainY[2]]\n",
    "indexTrain=np.arange(len(trainX_all))\n",
    "np.random.shuffle(indexTrain)\n",
    "trainX_sh=trainX_all[indexTrain]\n",
    "trainY_sh=trainY_all[indexTrain]\n",
    "testX_all=np.r_[testX[0],testX[1],testX[2]]\n",
    "testY_all=np.r_[testY[0],testY[1],testY[2]]\n",
    "indexTest=np.arange(len(testX_all))\n",
    "np.random.shuffle(indexTest)\n",
    "testX_sh=testX_all[indexTest]\n",
    "testY_sh=testY_all[indexTest]\n",
    "\n",
    "trainX_sh[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "test_data=[]\n",
    "for i in range(len(trainX_sh)):\n",
    "    train_data.append([trainX_sh[i],trainY_sh[i]])\n",
    "for i in range(len(testX_sh)):\n",
    "    train_data.append([testX_sh[i],testY_sh[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[tensor([[7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000]], dtype=torch.float64), tensor([2., 2., 1.])]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X in train_dataloader:\n",
    "    # print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(X)\n",
    "    # print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[tensor([[4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000]], dtype=torch.float64), tensor([0., 2., 1.])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}