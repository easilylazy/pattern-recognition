{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd03f857618d8b6a3d270a8a45aea13fd0dc2a28a907e8d4ef70fe87ce2a92698f8",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "author: leezeeyee   \n",
    "date: 2021/4/16  \n",
    "link: [github](https://github.com/easilylazy/pattern-recognition) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           1           5.1          3.5           1.4          0.2  setosa\n",
       "1           2           4.9          3.0           1.4          0.2  setosa\n",
       "2           3           4.7          3.2           1.3          0.2  setosa\n",
       "3           4           4.6          3.1           1.5          0.2  setosa\n",
       "4           5           5.0          3.6           1.4          0.2  setosa"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "irisData=pd.read_csv('../multiClass/iris.csv')\n",
    "irisData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 0              81\n",
       "Sepal.Length           5.5\n",
       "Sepal.Width            2.4\n",
       "Petal.Length           3.8\n",
       "Petal.Width            1.1\n",
       "Species         versicolor\n",
       "Name: 80, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "irisData.iloc[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDict={}\n",
    "labelDict['setosa']=0\n",
    "labelDict['versicolor']=1\n",
    "labelDict['virginica']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=irisData[['Sepal.Length',\t'Sepal.Width',\t'Petal.Length',\t'Petal.Width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "setosa\n0\nversicolor\n1\nvirginica\n2\n"
     ]
    }
   ],
   "source": [
    "labels=np.zeros(len(data))\n",
    "\n",
    "for key in labelDict:\n",
    "    print(key)\n",
    "    print(labelDict[key])\n",
    "    # print( irisData[irisData['Species']==key].index.tolist())\n",
    "    labels[irisData[irisData['Species']==key].index.tolist()]=labelDict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data\n",
    "one_hot_Y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17 13 20 25  8 26 49  0 35 28  6 22 36 24 34 46  2 12 16  3 43  7  9 38\n",
      "  5 41 11 47 15  4 44 40 29 23 31 37 33 21 30 14 39 48 18 10 42 45 27 32\n",
      "  1 19]\n",
      "[71 55 96 80 64 85 91 62 90 53 54 98 86 93 59 76 99 52 51 66 97 83 94 63\n",
      " 81 58 82 68 61 65 73 78 50 69 77 57 92 95 56 89 74 87 67 84 70 79 60 72\n",
      " 88 75]\n",
      "[149 128 112 100 115 108 106 134 105 147 136 130 146 117 111 132 138 109\n",
      " 143 124 121 120 113 145 116 141 119 135 133 148 118 107 131 114 137 122\n",
      " 125 103 123 110 144 140 129 127 142 104 102 126 139 101]\n",
      "[5.9 3.  5.1 1.8]\n",
      "[5.9 3.  5.1 1.8]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[6.5, 3. , 5.2, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.5, 2.4, 3.7, 1. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "trainX=[]\n",
    "trainY=[]\n",
    "testX=[]\n",
    "testY=[]\n",
    "\n",
    "for i in range(3):\n",
    "    index=np.where(labels==i)[0]\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    trainX.append(X[index[:30]])\n",
    "    trainY.append(labels[index[:30]])\n",
    "    testX.append(X[index[30:]])\n",
    "    testY.append(labels[index[30:]])\n",
    "    print(index)\n",
    "print(trainX[2][0])\n",
    "print(X[index[0]])\n",
    "trainX_all=np.r_[trainX[0],trainX[1],trainX[2]]\n",
    "trainY_all=np.r_[trainY[0],trainY[1],trainY[2]]\n",
    "indexTrain=np.arange(len(trainX_all))\n",
    "np.random.shuffle(indexTrain)\n",
    "trainX_sh=trainX_all[indexTrain]\n",
    "trainY_sh=trainY_all[indexTrain]\n",
    "testX_all=np.r_[testX[0],testX[1],testX[2]]\n",
    "testY_all=np.r_[testY[0],testY[1],testY[2]]\n",
    "indexTest=np.arange(len(testX_all))\n",
    "np.random.shuffle(indexTest)\n",
    "testX_sh=testX_all[indexTest]\n",
    "testY_sh=testY_all[indexTest]\n",
    "\n",
    "trainX_sh[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_sh=trainX_sh.astype(np.float32)\n",
    "testX_sh=testX_sh.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "test_data=[]\n",
    "for i in range(len(trainX_sh)):\n",
    "    train_data.append([trainX_sh[i],trainY_sh[i]])\n",
    "for i in range(len(testX_sh)):\n",
    "    train_data.append([testX_sh[i],testY_sh[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[tensor([[7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000]]), tensor([2., 0., 2.])]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X in train_dataloader:\n",
    "    # print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(X)\n",
    "    # print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[tensor([[4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000]]), tensor([0., 2., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature batch shape: torch.Size([3, 4])\n",
      "Labels batch shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "source": [
    "## model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 8),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(8, 3),\n",
    "            nn.Linear(8, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "source": [
    "## train & test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        y=torch.tensor(y,dtype=torch.long)\n",
    "        # print(pred,y)\n",
    "        # print('sf')\n",
    "        # print(pred[0][y[0]])\n",
    "        loss = loss_fn(pred, y)\n",
    "        # loss=(pred-y)**2\n",
    "        # print(pred.argmax(1)==y)\n",
    "\n",
    "        # print(loss)\n",
    "        # print(loss.grad_fn)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 8 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            y=torch.tensor(y,dtype=torch.long)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # print(pred)\n",
    "            # print(pred.argmax(1))\n",
    "            # print(y)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    if epoch%10==0:\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 33.3%, Avg loss: 0.367023 \n",
      "\n",
      "0.36702303210894266\n",
      "0.3333333333333333\n",
      "0.33954878250757853\n",
      "0.4866666666666667\n",
      "0.3133301270008087\n",
      "0.96\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.145901 \n",
      "\n",
      "0.117352454662323\n",
      "0.9666666666666667\n",
      "0.10850523906449477\n",
      "0.9733333333333334\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.090979 \n",
      "\n",
      "0.08409249761452277\n",
      "0.98\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.062719 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.047911 \n",
      "\n",
      "0.04006105326736967\n",
      "0.9866666666666667\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.037750 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.031947 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.030874 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.029831 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.024992 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "# fig=plt.figure()\n",
    "maxCorrect=0\n",
    "for t in range(epochs):\n",
    "    \n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    loss,correct=test(train_dataloader, model,t)\n",
    "    if correct>maxCorrect:\n",
    "        print(loss)\n",
    "        print(correct)\n",
    "        maxCorrect=correct\n",
    "        if abs(maxCorrect-1)<1e-6:\n",
    "            break\n",
    "    # plt.plot(t,loss,'o')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}