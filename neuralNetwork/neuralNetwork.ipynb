{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd03f857618d8b6a3d270a8a45aea13fd0dc2a28a907e8d4ef70fe87ce2a92698f8",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "source": [
    "##\n",
    "\n",
    "$D=\\left\\{\\left({\\vec{x}}_1,y_1\\right)=\\left(\\left(1,1\\right)^T,1\\right),\\left({\\vec{x}}_2,y_2\\right)=\\left(\\left(-1,-1\\right)^T,1\\right),\\left({\\vec{x}}_3,y_3\\right)=\\left(\\left(-1,1\\right)^T,-1\\right),\\left({\\vec{x}}_4,y_4\\right)=\\left(\\left(1,-1\\right)^T,-1\\right)\\right\\}$, 假设某神经网络结构为第一层有两个神经元，第二层有三个神经元，第三层有一个神经元，前两层每个神经元的激活函数为ReLU（即$x_d^{(l)}=\\max(0,\\ s_d^{(l)}$)，这里$s_d^{(l)}$代表第l层第d个神经元的输入，$x_d^{(l)}$代表该神经元的输出），第三层为线性输出，即$\\hat{y}=s_1^{(3)}$。误差函数为：$E_{in}=\\frac{1}{N}\\sum_{n}{(y_n-{\\hat{y}}_n)}^2$ ，学习率为0.01。假设初始权系数矩阵定义如下：\n",
    "$$\\mathbf{w}_0^{(1)}=\\left(\\begin{matrix}1&1\\\\1&1\\\\1&1\\\\\\end{matrix}\\right)，\\mathbf{w}_0^{(2)}=\\left(\\begin{matrix}1&1&1\\\\1&1&1\\\\1&1&1\\\\\\end{matrix}\\right)，\\mathbf{w}_0^{(3)}=\\left(\\begin{matrix}\\begin{matrix}1\\\\1\\\\\\end{matrix}\\\\\\begin{matrix}1\\\\1\\\\\\end{matrix}\\\\\\end{matrix}\\right)$$\n",
    "其中w的下标0代表迭代次数为0（即初始状态），上标数字分别代表第1、2、3层。要求将上述训练样本集的样本用反向传播法按顺序进行一轮训练，写出每一次迭代时各层的权系数矩阵，即：t=1时，进入样本{\\vec{x}}_1，得到$\\mathbf{w}_1^{(1)}、w1(2)和w1(3)$；t=2时，进入样本${\\vec{x}}_2$，得到$\\mathbf{w}_2^{(1)}、w2(2)和w2(3)$；t=3时，进入样本${\\vec{x}}_3$，得到$\\mathbf{w}_3^{(1)}、w3(2)和w3(3)$；t=4时，进入样本{\\vec{x}}_4，得到$\\mathbf{w}_4^{(1)}、w4(2)和w4(3)$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=np.asarray([[1,1],[-1,-1],[-1,1],[1,-1]])\n",
    "Y=np.array([1,1,-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addBias(X):\n",
    "    '''\n",
    "    为维数为N,d的向量X添加偏置向量\n",
    "    Args:\n",
    "        X(numpy.ndarray):shape为[N,d]\n",
    "    Returns:\n",
    "        numpy.ndarray:shape为[N,d+1]，且第一列列向量全为1\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        d=X.shape[1]\n",
    "        N=X.shape[0]\n",
    "        bias_vector=np.ones([N,1])\n",
    "        return np.column_stack((bias_vector,X))\n",
    "    except:\n",
    "        return np.append(1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1., -1., -1.],\n",
       "       [ 1., -1.,  1.],\n",
       "       [ 1.,  1., -1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "addBias(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "addBias(np.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(X):\n",
    "    '''\n",
    "    return max(0,x)\n",
    "    '''\n",
    "    try:\n",
    "        X[X<0]=0\n",
    "        return X\n",
    "    except:\n",
    "        X=np.asarray(X)\n",
    "        X[X<0]=0\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3. , 2.3, 0. ])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "Relu(np.asarray([3,2.3,-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo=np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=np.ones([3,2])\n",
    "W2=np.ones([3,3])\n",
    "W3=np.ones([4,1])"
   ]
  },
  {
   "source": [
    "## forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3. 3.]\n[3. 3.]\n[7. 7. 7.]\n[7. 7. 7.]\n[22.]\n[441.]\n"
     ]
    }
   ],
   "source": [
    "D1=D[0]\n",
    "Db=addBias(D)\n",
    "Db1=Db[0]\n",
    "y=Y[0]\n",
    "X1=np.dot(Db1,W1)\n",
    "print(X1)\n",
    "Y1=Relu(X1)\n",
    "print(Y1)\n",
    "Yb1=addBias(Y1)\n",
    "X2=np.dot(Yb1,W2)\n",
    "print(X2)\n",
    "Y2=Relu(X2)\n",
    "print(X2)\n",
    "Yb2=addBias(Y2)\n",
    "X3=np.dot(Yb2,W3)\n",
    "print(X3)\n",
    "Y3=X3\n",
    "E=(y-Y3)**2\n",
    "print(E)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}